# -*- coding: utf-8 -*-
"""audio_kokoro_final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Di46T9yM2gj4_sZ6gHNpwk5cP95RHdU8
"""

# Commented out IPython magic to ensure Python compatibility.
# install large file storage system for git
!git lfs install
# clone the HuggingFace model to local folder
!git clone https://huggingface.co/hexgrad/Kokoro-82M
# go into the model folder
# %cd Kokoro-82M
# install espeak-ng
!apt-get -qq -y install espeak-ng > /dev/null 2>&1
# install necessary dependencies for Python code
!pip install -q phonemizer torch transformers scipy munch

import os
os.environ["PHONEMIZER_ESPEAK_LIBRARY"] = r"C:\Program Files\eSpeak NG\libespeak-ng.dll"
os.environ["PHONEMIZER_ESPEAK_PATH"] = r"C:\Program Files\eSpeak NG\espeak-ng.exe"

print("PHONEMIZER_ESPEAK_LIBRARY:", os.environ.get("PHONEMIZER_ESPEAK_LIBRARY"))
print("PHONEMIZER_ESPEAK_PATH:", os.environ.get("PHONEMIZER_ESPEAK_PATH"))

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/Kokoro-82M

import sys
sys.path.append('/content/AI_Intro/tts')  # Adjust if 'models' is in a different location, like '/content/AI_Intro'

!pip install -q kokoro>=0.9.2 soundfile
!apt-get -qq -y install espeak-ng > /dev/null 2>&1

from kokoro import KPipeline
from IPython.display import display, Audio
import soundfile as sf
import torch

pipeline = KPipeline(lang_code='a')
text = '''
[Kokoro](/kˈOkəɹO/) is an open-weight TTS model with 82 million parameters. Despite its lightweight architecture, it delivers comparable quality to larger models while being significantly faster and more cost-efficient. With Apache-licensed weights, [Kokoro](/kˈOkəɹO/) can be deployed anywhere from production environments to personal projects.
'''
generator = pipeline(text, voice='af_heart')
for i, (gs, ps, audio) in enumerate(generator):
    print(i, gs, ps)
    display(Audio(data=audio, rate=24000, autoplay=i==0))
    sf.write(f'{i}.wav', audio, 24000)

# Define the four social media posts
texts = [
    # Technology
    '''
    Get ready to revolutionize your world with the new Quantum X Smartphone! Lightning-fast, stunning visuals, and AI that feels like magic! Unlock your future today!
    ''',
    # Cosmetics
    '''
    Shine bright with GlowVibe Cosmetics! Our new Rainbow Glow Palette brings vibrant colors and long-lasting sparkle to your makeup game! Feel fabulous, look flawless!
    ''',
    # Clothes
    '''
    Step into style with TrendyTreads' Summer Collection! Breezy fabrics, bold patterns, and endless comfort! Dress up, feel amazing, and own the season!
    ''',
    # Food
    '''
    Craving something delicious? Bite into BurgerBonanza’s Gourmet Stack! Juicy, flavorful, and packed with love! Your taste buds will thank you!
    '''
]

# Output filenames
output_files = [
    "tech_audio",
    "cosmetics_audio",
    "clothes_audio",
    "food_audio"
]

# Initialize the pipeline
pipeline = KPipeline(lang_code='a')

# Generate audio for each text
for text, output_base in zip(texts, output_files):
    print(f"Generating audio for {output_base}...")
    generator = pipeline(text, voice='af_heart')

    # Process generator output
    for i, (gs, ps, audio) in enumerate(generator):
        print(f"Segment {i}: gs={gs}, ps={ps}")
        # Display audio (autoplay only for the first segment)
        display(Audio(data=audio, rate=24000, autoplay=i==0))
        # Save audio
        output_file = f"{output_base}_{i}.wav"
        sf.write(output_file, audio, 24000)
        print(f"Saved as {output_file}")